# Placeholder for task_pipeline.py
# task_pipeline.py

from utils.lang_detector import detect_language
from utils.sentence_splitter import split_sentences

def run_pipeline(text, extractor, classifier, contextualiser, tracer, supervisor):
    """
    Ex√©cute le pipeline complet d'analyse d'un texte scientifique pour d√©tecter, classer
    et contextualiser les citations de donn√©es.

    Args:
        text (str): Texte int√©gral de l‚Äôarticle scientifique.
        extractor (ExtractionAgent): Agent charg√© d'extraire les mentions de donn√©es.
        classifier (ClassificationAgent): Agent charg√© de d√©terminer le type de donn√©es.
        contextualiser (ContextualisationAgent): Agent charg√© de r√©sumer le contexte d‚Äôusage.
        tracer (TraceAgent): Agent charg√© d‚Äôidentifier la source des donn√©es.
        supervisor (SupervisorAgent): Agent coordonnant et validant l‚Äôensemble.

    Returns:
        list[dict]: Liste des objets contenant les r√©sultats consolid√©s par mention de donn√©es.
    """

    lang = detect_language(text)
    sentences = split_sentences(text, lang=lang)

    extracted_mentions = []
    for idx, sentence in enumerate(sentences):
        if not sentence.strip():
            continue

        mentions = extractor.extract_data_mentions(sentence)
        for citation in mentions:
            extracted_mentions.append({
                "index": idx,
                "text": citation["text"] if isinstance(citation, dict) and "text" in citation else citation
            })

    # üí° D√©l√©gation de la classification + contextualisation + tra√ßage au superviseur
    results = supervisor.review_results(extracted_mentions, classifier, contextualiser, tracer)
    return results

