# Placeholder for extraction_agent.py
import re

class ExtractionAgent:
    def __init__(self):
        self.name = "ExtractionAgent"

    def extract_data_mentions(self, text):
        """
        RepÃ¨re les phrases contenant des rÃ©fÃ©rences Ã  des donnÃ©es,
        en utilisant une liste multilingue de mots-clÃ©s.

        Args:
            text (str): Texte complet de l'article scientifique.

        Returns:
            list[dict]: Liste des phrases suspectÃ©es de mentionner des donnÃ©es,
                        contenant l'index et le texte.
        """
        data_keywords = [
            # ğŸ”· FranÃ§ais - Termes gÃ©nÃ©raux
            r"\bdonnÃ©es?\b", r"\bsources?\b", r"\bjeux?\sde\sdonnÃ©es\b",
            r"\bjeux?\sde\sd[Ã©e]p[Ã¢a]rt\b", r"\bmat[Ã©e]riau[x]?\sde\sbase\b",
            
            # ğŸ”¹ FranÃ§ais - Collecte
            r"\brecueilli[e]?s?\b", r"\bcollect[Ã©e]?s?\b", r"\bobtenu[e]?s?\b",
            r"\bmesur[Ã©e]?s?\b", r"\bpr[Ã©e]lev[Ã©e]?s?\b", r"\bacquis[e]?s?\b",
            r"\bengrang[Ã©e]?s?\b", r"\bg[Ã©e]n[Ã©e]r[Ã©e]?s?\b",
            
            # ğŸ”¹ FranÃ§ais - Traitement
            r"\btrait[Ã©e]?s?\b", r"\btransform[Ã©e]?s?\b", r"\bnettoy[Ã©e]?s?\b",
            r"\bstandardis[Ã©e]?s?\b", r"\bfiltr[Ã©e]?s?\b", r"\bcorrig[Ã©e]?s?\b",
            r"\banonymis[Ã©e]?s?\b", r"\bagr[Ã©e]g[Ã©e]?s?\b",
            
            # ğŸ”¹ FranÃ§ais - Sources
            r"\bbases?\sde\sdonn[Ã©e]es\b", r"\bentrep[Ã´o]ts?\sde\sdonn[Ã©e]es\b",
            r"\barchives?\b", r"\brepositoires?\b", r"\bregistres?\b",
            r"\bcatalogues?\b", r"\binventaires?\b",
            
            # ğŸ”¹ FranÃ§ais - Types
            r"\bstatistiques?\b", r"\bm[Ã©e]triques?\b", r"\bindicateurs?\b",
            r"\bobservations?\b", r"\bvariables?\b", r"\bparam[Ã¨e]tres?\b",
            r"\bÃ©chantillons?\b", r"\bs[Ã©e]ries?\stemporelles\b",
            
            # ğŸ”· Anglais - General Terms
            r"\bdata\b", r"\bdataset[s]?\b", r"\braw\sdata\b",
            r"\bsource\sdata\b", r"\bprimary\sdata\b", r"\bsecondary\sdata\b",
            
            # ğŸ”¸ Anglais - Collection
            r"\bcollected\b", r"\bgathered\b", r"\bacquired\b",
            r"\bmeasured\b", r"\bsampled\b", r"\bgenerated\b",
            r"\bharvested\b", r"\bcompiled\b",
            
            # ğŸ”¸ Anglais - Processing
            r"\bprocessed\b", r"\bcleaned\b", r"\bnormalized\b",
            r"\bfiltered\b", r"\banonymized\b", r"\baggregated\b",
            r"\btransformed\b", r"\bcurated\b",
            
            # ğŸ”¸ Anglais - Sources
            r"\bdatabase[s]?\b", r"\bdata\swarehouse[s]?\b", r"\barchive[s]?\b",
            r"\brepository[\w]*\b", r"\bregistry[\w]*\b", r"\bcatalog[\w]*\b",
            
            # ğŸ”¸ Anglais - Types
            r"\bstatistics?\b", r"\bmetrics?\b", r"\bindicators?\b",
            r"\bobservations?\b", r"\bvariables?\b", r"\bparameters?\b",
            r"\bsamples?\b", r"\btime\sseries\b",
            
            # ğŸ”¶ Termes techniques communs
            r"\b(?:csv|json|xml)\s?files?\b", r"\b(?:excel|spreadsheet)s?\b",
            r"\bsql\s(?:tables?|databases?)\b", r"\bno[s]?ql\sstores?\b",
            r"\b(?:api|web)\s?services?\b", r"\b(?:ftp|sftp)\s?servers?\b",
            
            # ğŸ”· Expressions contextuelles franÃ§aises
            r"\bdonnÃ©es?\s(?:brutes?|originales?|expÃ©rimentales?)\b",
            r"\banalyses?\s(?:statistiques?|de\sdonnÃ©es?)\b",
            r"\btraitement\s(?:automatique|manuel)\sdes\sdonnÃ©es\b",
            
            # ğŸ”¸ English Contextual Phrases
            r"\bdata\s(?:mining|analysis|visualization)\b",
            r"\b(?:statistical|quantitative)\sanalysis\b",
            r"\b(?:machine\slearning|ai)\sdatasets?\b",
            
            # ğŸ†• Nouveaux termes scientifiques (2023-2024)
            r"\bsynthetic\sdata\b", r"\bdata\sfabric\b",
            r"\bdata\smesh\b", r"\bdata\sproducts?\b",
            r"\bdonnÃ©es?\ssynthÃ©tiques\b", r"\btissu\sde\sdonnÃ©es\b"
        ]

        pattern = re.compile("|".join(data_keywords), re.IGNORECASE)
        sentences = re.split(r'(?<=[.!?])\s+', text)

        mentions = []
        for idx, sentence in enumerate(sentences):
            if pattern.search(sentence) and len(sentence.strip()) > 20:
                mentions.append({
                    "index": idx,
                    "text": sentence.strip()
                })

        return mentions
